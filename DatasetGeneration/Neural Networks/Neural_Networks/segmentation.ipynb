{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-06-23T15:51:25.335688Z",
     "start_time": "2024-06-23T15:51:25.331818Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip install matplotlib tqdm pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a152ce93-54f1-499f-b3f2-2893a7237ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d6ff445f7dd6e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T19:52:17.921176Z",
     "start_time": "2024-07-13T19:51:35.098371Z"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image, ImageFilter\n",
    "from sklearn.model_selection import ParameterGrid, KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data import Subset\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms.functional import crop\n",
    "from tqdm import tqdm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c3cc274f6f48ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:42:31.836349Z",
     "start_time": "2024-07-13T15:42:31.834190Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(message)s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9270bcb59d05d024",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:42:31.852627Z",
     "start_time": "2024-07-13T15:42:31.836349Z"
    }
   },
   "outputs": [],
   "source": [
    "image_dir = '../Data/Picture_Caustic'\n",
    "mask_dir = '../Data/Caustic_Seg'\n",
    "\n",
    "image_files = os.listdir(image_dir)\n",
    "mask_files = os.listdir(mask_dir)\n",
    "\n",
    "# Validate that each image has a corresponding mask\n",
    "valid_pairs = [(img, img) for img in image_files if img in mask_files]\n",
    "\n",
    "print(f\"Found {len(valid_pairs)} valid image-mask pairs out of {len(image_files)} images.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74aab0b4d9c28aaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:42:31.859593Z",
     "start_time": "2024-07-13T15:42:31.853634Z"
    }
   },
   "outputs": [],
   "source": [
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, indices=None, transform=None, crop_size=(256, 256), max_blur_radius=2, is_train=True):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.transform = transform\n",
    "        self.crop_size = crop_size\n",
    "        self.max_blur_radius = max_blur_radius\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Load images and masks into a dictionary\n",
    "        self.data_dict = self._load_data()\n",
    "        self.images = list(self.data_dict.keys())\n",
    "\n",
    "        # Subset the dataset based on provided indices\n",
    "        if indices is not None:\n",
    "            self.images = [self.images[i] for i in indices]\n",
    "\n",
    "    def _load_data(self):\n",
    "        data_dict = {}\n",
    "        image_files = os.listdir(self.image_dir)\n",
    "        \n",
    "        for img_name in image_files:\n",
    "            img_path = os.path.join(self.image_dir, img_name)\n",
    "            mask_path = os.path.join(self.mask_dir, img_name)\n",
    "            \n",
    "            if os.path.exists(mask_path):\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "                mask = Image.open(mask_path).convert(\"L\")\n",
    "                data_dict[img_name] = (image, mask)\n",
    "        \n",
    "        return data_dict\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.images[idx]\n",
    "        image, mask = self.data_dict[img_name]\n",
    "        \n",
    "        if self.is_train:\n",
    "            # Determine the crop size dynamically\n",
    "            original_width, original_height = image.size\n",
    "            crop_width = random.randint(int(original_width * 0.25), original_width)\n",
    "            crop_height = random.randint(int(original_height * 0.25), original_height)\n",
    "            \n",
    "            # Apply random crop\n",
    "            i, j, h, w = transforms.RandomCrop.get_params(image, output_size=(crop_height, crop_width))\n",
    "            image = transforms.functional.crop(image, i, j, h, w)\n",
    "            mask = transforms.functional.crop(mask, i, j, h, w)\n",
    "            \n",
    "            # Apply random blur to the image\n",
    "            blur_radius = random.uniform(0, self.max_blur_radius)\n",
    "            image = image.filter(ImageFilter.GaussianBlur(blur_radius))\n",
    "            \n",
    "            # Apply random horizontal flip with 50/50 chance\n",
    "            if random.random() > 0.5:\n",
    "                image = transforms.functional.hflip(image)\n",
    "                mask = transforms.functional.hflip(mask)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            mask = self.transform(mask)\n",
    "\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ca313eeae245f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:42:32.292903Z",
     "start_time": "2024-07-13T15:42:32.289390Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_split_directories(full_dataset, base_dir, train_indices, val_indices, test_indices):\n",
    "    \"\"\"Create directories for train, val, and test splits and copy images and masks.\"\"\"\n",
    "    for split, indices in zip(['train', 'val', 'test'], [train_indices, val_indices, test_indices]):\n",
    "        split_dir = os.path.join(base_dir, split)\n",
    "        img_split_dir = os.path.join(split_dir, 'imgs')\n",
    "        mask_split_dir = os.path.join(split_dir, 'masks')\n",
    "        \n",
    "        os.makedirs(img_split_dir, exist_ok=True)\n",
    "        os.makedirs(mask_split_dir, exist_ok=True)\n",
    "        \n",
    "        for idx in indices:\n",
    "            img_name = full_dataset.images[idx]\n",
    "            img_src = os.path.join(image_dir, img_name)\n",
    "            mask_src = os.path.join(mask_dir, img_name)\n",
    "            \n",
    "            img_dst = os.path.join(img_split_dir, img_name)\n",
    "            mask_dst = os.path.join(mask_split_dir, img_name)\n",
    "            \n",
    "            shutil.copy(img_src, img_dst)\n",
    "            shutil.copy(mask_src, mask_dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8b5db56ddb0690",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:43:17.347297Z",
     "start_time": "2024-07-13T15:42:34.663137Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((256, 256)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "full_dataset = SegmentationDataset(image_dir, mask_dir, transform=transform)\n",
    "full_dataloader = DataLoader(full_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715f459ac5d38b56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:43:17.351024Z",
     "start_time": "2024-07-13T15:43:17.348305Z"
    }
   },
   "outputs": [],
   "source": [
    "# Test the dataloader\n",
    "def testing_dataloader(dataloader):\n",
    "    for i, (images, masks) in enumerate(dataloader):\n",
    "        print(f'Batch {i+1}')\n",
    "        print(f'Images shape: {images.shape}')\n",
    "        print(f'Masks shape: {masks.shape}')\n",
    "        if i == 2:  # Test with the first 3 batches\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f60e12e0382107",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:43:17.806508Z",
     "start_time": "2024-07-13T15:43:17.351024Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Testing full dataloader\")\n",
    "testing_dataloader(full_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd7a6e2df686141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:43:17.811736Z",
     "start_time": "2024-07-13T15:43:17.807515Z"
    }
   },
   "outputs": [],
   "source": [
    "# Split dataset into train, val, and test sets\n",
    "train_val_indices, test_indices = train_test_split(range(len(full_dataset)), test_size=0.2, random_state=42)\n",
    "train_indices, val_indices = train_test_split(train_val_indices, test_size=0.25, random_state=42)  # 0.25 * 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdbecc012ff9391",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:44:14.092486Z",
     "start_time": "2024-07-13T15:43:17.812743Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create split directories and copy data\n",
    "base_dir = '../Data/split'\n",
    "create_split_directories(full_dataset, base_dir, train_indices, val_indices, test_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdff8c0480381d64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:44:14.096147Z",
     "start_time": "2024-07-13T15:44:14.092486Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define paths for splits\n",
    "train_image_dir = os.path.join(base_dir, 'train', 'imgs')\n",
    "train_mask_dir = os.path.join(base_dir, 'train', 'masks')\n",
    "val_image_dir = os.path.join(base_dir, 'val', 'imgs')\n",
    "val_mask_dir = os.path.join(base_dir, 'val', 'masks')\n",
    "test_image_dir = os.path.join(base_dir, 'test', 'imgs')\n",
    "test_mask_dir = os.path.join(base_dir, 'test', 'masks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eee2f14149e40ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:44:57.615620Z",
     "start_time": "2024-07-13T15:44:14.096147Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create datasets and dataloaders\n",
    "train_dataset = SegmentationDataset(train_image_dir, train_mask_dir, transform=transform)\n",
    "val_dataset = SegmentationDataset(val_image_dir, val_mask_dir, transform=transform)\n",
    "test_dataset = SegmentationDataset(test_image_dir, test_mask_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c6d2f93718e213",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:44:57.619106Z",
     "start_time": "2024-07-13T15:44:57.615620Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5710c9aa2fed252",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:44:58.252985Z",
     "start_time": "2024-07-13T15:44:57.619106Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Testing train_dataloader\")\n",
    "testing_dataloader(train_dataloader)\n",
    "\n",
    "print(\"Testing val_dataloader\")\n",
    "testing_dataloader(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f3b65820725730",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:44:59.506799Z",
     "start_time": "2024-07-13T15:44:58.253993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Display some sample images and masks from the training dataset\n",
    "def show_sample_images(dataset, title, num_samples=4):\n",
    "    fig, ax = plt.subplots(num_samples, 2, figsize=(10, 10))\n",
    "    for i in range(num_samples):\n",
    "        img, mask = dataset[i]\n",
    "        ax[i, 0].imshow(img.permute(1, 2, 0))\n",
    "        ax[i, 0].set_title(title)\n",
    "        ax[i, 0].axis('off')  \n",
    "        \n",
    "        ax[i, 1].imshow(mask.squeeze(), cmap='gray')\n",
    "        ax[i, 1].set_title(title)\n",
    "        ax[i, 1].axis('off')\n",
    "    plt.show()\n",
    "\n",
    "print(\"Training Samples:\")\n",
    "show_sample_images(train_dataset, \"Train\")\n",
    "\n",
    "print(\"Validation Samples:\")\n",
    "show_sample_images(val_dataset, \"Validation\")\n",
    "\n",
    "print(\"Testing Samples:\")\n",
    "show_sample_images(test_dataset, \"Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea1f3770c8433691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:44:59.510404Z",
     "start_time": "2024-07-13T15:44:59.506799Z"
    }
   },
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d797b45bcc9ef2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:44:59.522199Z",
     "start_time": "2024-07-13T15:44:59.510404Z"
    }
   },
   "outputs": [],
   "source": [
    "class DownSampleLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(DownSampleLayer, self).__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de44bf689e9d423b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:44:59.533989Z",
     "start_time": "2024-07-13T15:44:59.522199Z"
    }
   },
   "outputs": [],
   "source": [
    "class UpSampleLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super(UpSampleLayer, self).__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = nn.functional.pad(x1, [diffX // 2, diffX - diffX // 2, diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d001024f14785f5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:44:59.544883Z",
     "start_time": "2024-07-13T15:44:59.533989Z"
    }
   },
   "outputs": [],
   "source": [
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e71a19fdbd799ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:44:59.555702Z",
     "start_time": "2024-07-13T15:44:59.544883Z"
    }
   },
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = DownSampleLayer(64, 128)\n",
    "        self.down2 = DownSampleLayer(128, 256)\n",
    "        self.down3 = DownSampleLayer(256, 512)\n",
    "        self.down4 = DownSampleLayer(512, 512)\n",
    "        self.up1 = UpSampleLayer(1024, 256)\n",
    "        self.up2 = UpSampleLayer(512, 128)\n",
    "        self.up3 = UpSampleLayer(256, 64)\n",
    "        self.up4 = UpSampleLayer(128, 64)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbceeb435c25c57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:45:00.294665Z",
     "start_time": "2024-07-13T15:44:59.556707Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = UNet(n_channels=3, n_classes=1).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981d8a5ba159ac45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:45:00.298250Z",
     "start_time": "2024-07-13T15:45:00.294665Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44089f8d4bce3b48",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:45:00.309500Z",
     "start_time": "2024-07-13T15:45:00.298250Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    total_iou = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, masks in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "\n",
    "            iou = calculate_iou(preds, masks)\n",
    "            total_iou += iou * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "    \n",
    "    avg_iou = total_iou / total_samples\n",
    "    return avg_iou\n",
    "\n",
    "def calculate_iou(preds, masks):\n",
    "    preds = preds.int()\n",
    "    masks = masks.int()\n",
    "    intersection = (preds & masks).float().sum((1, 2))\n",
    "    union = (preds | masks).float().sum((1, 2))\n",
    "    iou = (intersection + 1e-6) / (union + 1e-6)\n",
    "    return iou.mean().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2691a55d59f12d47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:45:00.320767Z",
     "start_time": "2024-07-13T15:45:00.309500Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_model_with_iou_loss(model, dataloader):\n",
    "    model.eval()\n",
    "    total_iou = 0.0\n",
    "    total_samples = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, masks in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs) > 0.5\n",
    "\n",
    "            iou = calculate_iou(preds, masks)\n",
    "            total_iou += iou * inputs.size(0)\n",
    "            total_samples += inputs.size(0)\n",
    "    \n",
    "    avg_iou = total_iou / total_samples\n",
    "    avg_iou_loss = 1 - avg_iou  # IoU loss\n",
    "    return avg_iou_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a437da6033823e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:45:00.332257Z",
     "start_time": "2024-07-13T15:45:00.321774Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_optimizer(optimizer, model_parameters, lr, weight_decay):\n",
    "    if optimizer == 'adam':\n",
    "        return optim.Adam(model_parameters, lr=lr, weight_decay=weight_decay)\n",
    "    elif optimizer == 'sgd':\n",
    "        return optim.SGD(model_parameters, lr=lr, weight_decay=weight_decay, momentum=0.9)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown optimizer: {optimizer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37fe451a2e91f10",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:50:59.589615Z",
     "start_time": "2024-07-13T15:50:59.584631Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, dataloader, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for inputs, masks in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, masks)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "        \n",
    "        epoch_loss = running_loss / len(dataloader.dataset)\n",
    "        logging.info(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7ce6c015264f05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:54:58.299419Z",
     "start_time": "2024-07-13T15:54:58.295075Z"
    }
   },
   "outputs": [],
   "source": [
    "def cross_val_grid_search(model, criterion, full_dataset, param_grid, n_splits=5):\n",
    "    best_loss = float('inf')\n",
    "    best_params = None\n",
    "    param_combinations = list(ParameterGrid(param_grid))\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    for params in tqdm(param_combinations, desc=\"Hyperparameter combinations\"):\n",
    "        logging.info(f\"Testing with parameters: {params}\")\n",
    "        fold_losses = []\n",
    "        \n",
    "        for train_indices, val_indices in tqdm(kf.split(full_dataset), desc=\"Folds\", leave=False):\n",
    "            train_subset = Subset(full_dataset, train_indices)\n",
    "            val_subset = Subset(full_dataset, val_indices)\n",
    "            \n",
    "            train_dataloader = DataLoader(train_subset, batch_size=params['batch_size'], shuffle=True, num_workers=0)\n",
    "            val_dataloader = DataLoader(val_subset, batch_size=params['batch_size'], shuffle=False, num_workers=0)\n",
    "            \n",
    "            optimizer = get_optimizer(params['optimizer'], model.parameters(), params['lr'], params['weight_decay'])\n",
    "            \n",
    "            # Train the model\n",
    "            train_model(model, criterion, optimizer, train_dataloader, num_epochs=params['num_epochs'])\n",
    "            \n",
    "            # Evaluate the model using IoU loss\n",
    "            val_loss = evaluate_model_with_iou_loss(model, val_dataloader)\n",
    "            fold_losses.append(val_loss)\n",
    "        \n",
    "        avg_loss = sum(fold_losses) / len(fold_losses)\n",
    "        logging.info(f\"Average IoU Loss for parameters {params}: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Check if the current loss is the best (lowest)\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            best_params = params\n",
    "    \n",
    "    logging.info(f\"Best parameters: {best_params}, Best IoU Loss: {best_loss:.4f}\")\n",
    "    return best_params, best_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b347987e2a51dd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:55:01.517805Z",
     "start_time": "2024-07-13T15:55:01.514806Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'optimizer': ['adam'],\n",
    "    'lr': [1e-4, 1e-3, 1e-2, 1e-1],  \n",
    "    'weight_decay': [0, 1e-5, 1e-4, 1e-3],\n",
    "    'batch_size': [4, 8, 16],\n",
    "    'num_epochs': [10] \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb40b496e39ca4bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:51:16.231815Z",
     "start_time": "2024-07-13T15:51:15.593737Z"
    }
   },
   "outputs": [],
   "source": [
    "best_params, best_iou = cross_val_grid_search(model, criterion, full_dataset, param_grid, n_splits=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a471b786039601b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:42:22.538892Z",
     "start_time": "2024-07-13T15:42:22.535810Z"
    }
   },
   "outputs": [],
   "source": [
    "print(best_params, best_iou)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539c30649dbf6a8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:28:50.904294Z",
     "start_time": "2024-07-13T15:28:50.893027Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train the final model with best parameters\n",
    "best_model = UNet(n_channels=3, n_classes=1).to(device)\n",
    "# Train the final model with best parameters\n",
    "final_optimizer = get_optimizer(best_params['optimizer'], best_model.parameters(), best_params['lr'], best_params['weight_decay'])\n",
    "\n",
    "# Train the model\n",
    "train_model(best_model, criterion, final_optimizer, train_dataloader, num_epochs=best_params['num_epochs'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87952d9adb5581cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'trained_models/best_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "111484fc-091d-47c5-96bd-211702c15595",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:06:16.790649Z",
     "start_time": "2024-07-13T15:06:08.767283Z"
    }
   },
   "outputs": [],
   "source": [
    "# Evaluate the final model on the test dataset\n",
    "test_loss = evaluate_model(best_model, test_dataloader)\n",
    "logging.info(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0b451917fd2cd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-13T15:08:52.218864Z",
     "start_time": "2024-07-13T15:08:52.214978Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataloader, num_images=4):\n",
    "    model.eval()\n",
    "    images_so_far = 0\n",
    "    fig, axes = plt.subplots(num_images, 3, figsize=(15, num_images * 5))\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, masks) in enumerate(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            masks = masks.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = torch.sigmoid(outputs)\n",
    "\n",
    "            for j in range(inputs.size()[0]):\n",
    "                if images_so_far == num_images:\n",
    "                    return\n",
    "                axes[images_so_far, 0].imshow(inputs.cpu().data[j].permute(1, 2, 0))\n",
    "                axes[images_so_far, 0].set_title(\"Input Image\")\n",
    "                axes[images_so_far, 0].axis('off')\n",
    "                axes[images_so_far, 1].imshow(masks.cpu().data[j].squeeze(), cmap='gray')\n",
    "                axes[images_so_far, 1].set_title(\"Ground Truth Mask\")\n",
    "                axes[images_so_far, 1].axis('off')\n",
    "                axes[images_so_far, 2].imshow(preds.cpu().data[j].squeeze(), cmap='gray')\n",
    "                axes[images_so_far, 2].set_title(\"Predicted Mask\")\n",
    "                axes[images_so_far, 2].axis('off')\n",
    "                images_so_far += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298182e8-b2a7-401a-9f1c-1408ff5ca682",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(best_model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0a0b5ddfeeb08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final model with best hyperparameters on the full dataset\n",
    "final_model = UNet(n_channels=3, n_classes=1).to(device)\n",
    "final_criterion = nn.BCEWithLogitsLoss()\n",
    "final_optimizer = get_optimizer(best_params['optimizer'], best_model.parameters(), best_params['lr'], best_params['weight_decay'])\n",
    "\n",
    "train_model(final_model, final_criterion, final_optimizer, full_dataloader, num_epochs=best_params['num_epochs'])\n",
    "\n",
    "# Evaluate the final model on the test dataset\n",
    "test_loss = evaluate_model(best_model, test_dataloader)\n",
    "logging.info(f'Test Loss: {test_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f05bbcc02851c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_predictions(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781a452d-46c2-475b-b006-b689af0281df",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'trained_models/last_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
